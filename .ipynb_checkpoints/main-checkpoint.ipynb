{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:50:37.891902800Z",
     "start_time": "2023-07-22T16:50:37.882859400Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(1, 1, 1)\n",
    "eye_diff_list = []\n",
    "xx = []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap2 = cv2.VideoCapture(1)\n",
    "width=1920\n",
    "height = 1080\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "pTime = 0\n",
    "\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "drawSpecs = mpDraw.DrawingSpec(thickness=1, circle_radius=1)\n",
    "faceMesh = mpFaceMesh.FaceMesh(\n",
    "    static_image_mode = False,\n",
    "    max_num_faces = 3,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.74,\n",
    "    min_tracking_confidence = 0.75   # will we miss a lot of information with higher confidence threshold??\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:51:31.843070700Z",
     "start_time": "2023-07-22T16:51:24.730564800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def ear(x1, y1, x2, y2, x3, y3, x4, y4):\n",
    "    a = math.sqrt(math.pow((x2-x1), 2) + math.pow((y2-y1), 2))\n",
    "    b = math.sqrt(math.pow((x4-x3), 2) + math.pow((y4-y3), 2))\n",
    "    return b,a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:51:34.026671100Z",
     "start_time": "2023-07-22T16:51:34.026144300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{160, 33, 161, 163, 133, 7, 173, 144, 145, 246, 153, 154, 155, 157, 158, 159}\n",
      "{384, 385, 386, 387, 388, 390, 263, 362, 398, 466, 373, 374, 249, 380, 381, 382}\n",
      "{0, 267, 269, 270, 13, 14, 17, 402, 146, 405, 409, 415, 291, 37, 39, 40, 178, 308, 181, 310, 311, 312, 185, 314, 317, 318, 61, 191, 321, 324, 78, 80, 81, 82, 84, 87, 88, 91, 95, 375}\n",
      "{65, 66, 70, 105, 107, 46, 52, 53, 55, 63}\n",
      "{293, 295, 296, 300, 334, 336, 276, 282, 283, 285}\n",
      "{132, 389, 136, 10, 397, 400, 148, 149, 150, 21, 152, 284, 288, 162, 297, 172, 176, 54, 58, 323, 67, 454, 332, 338, 93, 356, 103, 361, 234, 109, 365, 379, 377, 378, 251, 127}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# # we can n dimensional numpy array with indxes wise alternate to features\n",
    "# n-dimensional numpy array, with each feature corresponding to each row.\n",
    "# as each feature has different number of landmarks, so dtype=object( learn it)\n",
    "# feature_indices = np.array([list(), list(), list(), list(), list(), list()], dtype=object);\n",
    "feature_indices = [set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set()]\n",
    "\n",
    "# LIST - feature_indices = [ [] [] [] [] [] [] ]\n",
    "for s, t in mpFaceMesh.FACEMESH_RIGHT_EYE:          # right eye      0\n",
    "    feature_indices[0].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_LEFT_EYE:           # left eye       1\n",
    "    feature_indices[1].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_LIPS:               # lips           2\n",
    "    feature_indices[2].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_RIGHT_EYEBROW:      # right eyebrow  3\n",
    "    feature_indices[3].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_LEFT_EYEBROW:       # left eyebrow   4\n",
    "    feature_indices[4].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_FACE_OVAL:          # oval           5\n",
    "    feature_indices[5].update([s, t])\n",
    "\n",
    "flat_feature_indices = [ j for i in feature_indices for j in i]\n",
    "# facial_indices = []\n",
    "\n",
    "le, re, lip, reb, leb, oval = len(feature_indices[0]), len(feature_indices[1]), len(feature_indices[2]), len(feature_indices[3]), len(feature_indices[4]),len(feature_indices[5])\n",
    "facial = 478 - le + re + lip + reb + oval\n",
    "feature_landmarks_count = [le, re, lip, reb, leb, oval, facial]\n",
    "\n",
    "current_landmarks = np.array([np.zeros(feature_landmarks_count[0]),\n",
    "                     np.zeros(feature_landmarks_count[1]),\n",
    "                     np.zeros(feature_landmarks_count[2]),\n",
    "                     np.zeros(feature_landmarks_count[3]),\n",
    "                     np.zeros(feature_landmarks_count[4]),\n",
    "                     np.zeros(feature_landmarks_count[5]),\n",
    "                     np.zeros(feature_landmarks_count[6])], dtype=object)\n",
    "# current_landmarks = np.array(current_landmarks, dtype=object)\n",
    "last_landmarks = np.array(np.copy(current_landmarks))\n",
    "\n",
    "cl = [0]*len(feature_indices[0])\n",
    "ll = [0]*len(feature_indices[0])\n",
    "\n",
    "curr_past = 0\n",
    "diff = 0\n",
    "fail_count = 0\n",
    "change_detected_count = 0\n",
    "\n",
    "current_landmark_list = np.array([0 for i in range(478)])\n",
    "last_landmark_list = np.array([0 for i in range(478)])\n",
    "\n",
    "diff_list = [0] * 7\n",
    "euclidean_distance_list = [0] * 7\n",
    "\n",
    "last_euclidean_distance_list = [0] * 8\n",
    "current_euclidean_distance_list = [0] * 8\n",
    "\n",
    "eye_diff_list = []\n",
    "\n",
    "current_facial_change = 0\n",
    "last_facial_change = 0\n",
    "\n",
    "\n",
    "blink_count = 0\n",
    "current_eye_state = 2\n",
    "\n",
    "\n",
    "# allImages = []\n",
    "# videoOutput = cv2.VideoWriter(\"eyeVideo.avi\", cv2.VideoWriter_fourcc(*'XVID'), 10, (640, 480))\n",
    "eye_diff_list = []\n",
    "xx = []\n",
    "\n",
    "# print(\"Current Landmarks : \", current_landmarks.shape)\n",
    "# print(\"Last Landmarks : \", last_landmarks.shape)\n",
    "# print(\"Feature indices : \", feature_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:48:49.249611Z",
     "start_time": "2023-07-22T16:48:43.516222100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T16:49:44.259105Z",
     "start_time": "2023-07-22T16:49:37.928411900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m imgRGB \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(img, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[0;32m     21\u001B[0m img_size \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m---> 23\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mfaceMesh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgRGB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(img\u001B[38;5;241m.\u001B[39mshape, np\u001B[38;5;241m.\u001B[39muint8)\n\u001B[0;32m     27\u001B[0m facial_distance \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\mediapipe\\python\\solutions\\face_mesh.py:125\u001B[0m, in \u001B[0;36mFaceMesh.process\u001B[1;34m(self, image)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, image: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NamedTuple:\n\u001B[0;32m    111\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Processes an RGB image and returns the face landmarks on each detected face.\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;124;03m    face landmarks on each detected face.\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 125\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001B[0m, in \u001B[0;36mSolutionBase.process\u001B[1;34m(self, input_data)\u001B[0m\n\u001B[0;32m    359\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    360\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph\u001B[38;5;241m.\u001B[39madd_packet_to_input_stream(\n\u001B[0;32m    361\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream_name,\n\u001B[0;32m    362\u001B[0m         packet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_packet(input_stream_type,\n\u001B[0;32m    363\u001B[0m                                  data)\u001B[38;5;241m.\u001B[39mat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_simulated_timestamp))\n\u001B[1;32m--> 365\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait_until_idle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \u001B[38;5;66;03m# output stream names.\u001B[39;00m\n\u001B[0;32m    368\u001B[0m solution_outputs \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mnamedtuple(\n\u001B[0;32m    369\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSolutionOutputs\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_stream_type_info\u001B[38;5;241m.\u001B[39mkeys())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "#       CSV DATA FILE OPENING\n",
    "field_names = [\"frame\", \"eye\", \"ear\",\"facial\"]\n",
    "state_string = \"Open\"\n",
    "frame, eye, eargraph, facial_change = 1,1,0,0\n",
    "with open('data.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "    csv_writer.writeheader()\n",
    "    info = {\"frame\": frame, \"eye\": eye, \"ear\": eargraph, \"facial\": facial_change}\n",
    "    csv_writer.writerow(info)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "i = -1\n",
    "while True:\n",
    "    with open(\"data.csv\", 'a') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        info = {\"frame\": frame, \"eye\": eye, \"ear\": eargraph, \"facial\": facial_change}\n",
    "        csv_writer.writerow(info)\n",
    "\n",
    "        success, img = cap.read()\n",
    "\n",
    "        img = cv2.flip(img, 1)\n",
    "        img.flags.writeable = False\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_size = img.shape\n",
    "\n",
    "        results = faceMesh.process(imgRGB)\n",
    "        img = np.zeros(img.shape, np.uint8)\n",
    "\n",
    "        facial_distance = 0\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            l = []\n",
    "            for faceLms in results.multi_face_landmarks:\n",
    "                # mpDraw.draw_landmarks(img, faceLms,\n",
    "                #                       mpFaceMesh.FACEMESH_CONTOURS,\n",
    "                #                       landmark_drawing_spec=drawSpecs,\n",
    "                #                       connection_drawing_spec=drawSpecs)\n",
    "\n",
    "                colors = [(0, 0, 0), (255, 255, 255), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0),(0, 0, 0)]\n",
    "\n",
    "                facial_indices = [ind for ind, x in enumerate(faceLms.landmark) if ind not in flat_feature_indices]\n",
    "                feature_indices[-1] = set(facial_indices)\n",
    "\n",
    "                angle_horizontal = 0\n",
    "                angle_vertical = 0\n",
    "\n",
    "                # facial_distance = 0\n",
    "\n",
    "                for cid, feature in enumerate(feature_indices):\n",
    "                    index = 0\n",
    "                    color_ind = 0\n",
    "                    # if cid == 2:\n",
    "                    euclidean_distance = 0\n",
    "                    point_count = 0\n",
    "                    for ind, lm in enumerate(faceLms.landmark):\n",
    "                        if ind in feature:\n",
    "                            # Coordinaated of every LANDMARK on FACE with origin\n",
    "                            x, y, z = int(img_size[1]*lm.x), int(img_size[0]*lm.y), lm.z\n",
    "\n",
    "                            if cid == 6:\n",
    "                                img = cv2.circle(img, (x, y), 1, (0, 255, 100), 2)\n",
    "                                facial_distance += pow(pow((x-0), 2) + pow((y-450), 2), 1/2)\n",
    "                                # img = cv2.line(img, (x,y), (a_oval_landmark[0], a_oval_landmark[1]), (0,0,0), 1)\n",
    "\n",
    "                            # SUM DISTANACE of evey LANDMARK on FACE with origin\n",
    "                            euclidean_distance += pow(pow(x, 2) + pow(y, 2), 1/2)\n",
    "                            # img = cv2.line(img, (0,0), (x,y), (255,255,0), 1)\n",
    "\n",
    "                            # POINTS in middle of FACE to CALCUALTE the VERTICAL/HORIZONTAL movement\n",
    "                            if ind == list(feature_indices[5])[3] or ind == list(feature_indices[5])[10]:\n",
    "                                a_oval_landmark = [x, y, z]\n",
    "                                img = cv2.circle(img, (x, y), 1, (0, 0, 255), 5)\n",
    "                                img = cv2.line(img, (x,y), (600,0), (0,255,0), 2)\n",
    "                                img = cv2.line(img, (x,y), (0,350), (255,255,1), 2)\n",
    "\n",
    "                                angle_vertical += pow(pow((x-600), 2) + pow((y-y), 2), 1/2)\n",
    "                                angle_horizontal += pow(pow((x-x), 2) + pow((y-350), 2), 1/2)\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "                            if curr_past == 0:\n",
    "                                last_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "                            elif curr_past % 1 == 0:\n",
    "                                current_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "\n",
    "\n",
    "                            index += 1\n",
    "                            color_ind += 1\n",
    "                            point_count += 1\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      COORDINATES EXTRACTION\n",
    "            # LIPS\n",
    "            # Coordinates\n",
    "            lx1, ly1 = int(faceLms.landmark[61].x*img_size[1]), int(faceLms.landmark[61].y*img_size[0])\n",
    "            lx2, ly2 = int(faceLms.landmark[291].x*img_size[1]), int(faceLms.landmark[291].y*img_size[0])\n",
    "            lx3, ly3 = int(faceLms.landmark[0].x*img_size[1]), int(faceLms.landmark[0].y*img_size[0])\n",
    "            lx4, ly4 = int(faceLms.landmark[17].x*img_size[1]), int(faceLms.landmark[17].y*img_size[0])\n",
    "\n",
    "            # euclidean aspect ratio\n",
    "            lipa, lipb = ear(lx1, ly1, lx2, ly2, lx3, ly3, lx4, ly4)\n",
    "            lip_euclidean = lipa + lipb\n",
    "\n",
    "            # LEFT EYE\n",
    "            # Coordinates\n",
    "            x1, y1 = int(faceLms.landmark[133].x*img_size[1]), int(faceLms.landmark[133].y*img_size[0])\n",
    "            x2, y2 = int(faceLms.landmark[33].x*img_size[1]), int(faceLms.landmark[33].y*img_size[0])\n",
    "            x4, y4 = int(faceLms.landmark[159].x*img_size[1]), int(faceLms.landmark[159].y*img_size[0])\n",
    "            x3, y3 = int(faceLms.landmark[145].x*img_size[1]), int(faceLms.landmark[145].y*img_size[0])\n",
    "\n",
    "            # euclidean aspect ratio\n",
    "            eyea, eyeb = ear(x1,y1,x2,y2,x3,y3,x4,y4)\n",
    "            euclidean = eyea/eyeb\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      LAST CURRENT UPDATION\n",
    "            if curr_past == 0:\n",
    "                last_euclidean_distance_list[cid] = euclidean_distance\n",
    "                last_facial_change = angle_vertical + angle_horizontal\n",
    "            else:\n",
    "                current_euclidean_distance_list[cid] = euclidean_distance\n",
    "                current_facial_change = angle_vertical + angle_horizontal\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      STATE OF EYE\n",
    "            if euclidean > 0.29 and (current_eye_state == 0 or current_eye_state == 1):#fully open\n",
    "                blink_count += 1\n",
    "                current_eye_state = 2\n",
    "                state_string = \"FULL OPEN\"\n",
    "            elif euclidean < 0.15 and (current_eye_state == 2 or current_eye_state == 1):\n",
    "                blink_count += 1\n",
    "                current_eye_state = 0\n",
    "                state_string = \"FULL CLOSED\"\n",
    "            elif 0.18 <= euclidean < 0.29 and (current_eye_state == 0 or current_eye_state == 2):\n",
    "                blink_count += 1\n",
    "                current_eye_state = 1\n",
    "                state_string = \"HALF OPEN/CLOSED\"\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      DISTANCES CALCULATION for GRAPH\n",
    "\n",
    "            for i in range(7):\n",
    "                # diff_list[i] = (sum((abs(last_landmarks-current_landmarks))[i]))/feature_landmarks_count[i]\n",
    "                diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))/feature_landmarks_count[i]\n",
    "                # diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))\n",
    "\n",
    "            frame = curr_past #current past frame\n",
    "            # eye = diff_list[0] if diff_list[0] > 1 else 1\n",
    "            zoop = (current_euclidean_distance_list[5]/feature_landmarks_count[5]) - (last_euclidean_distance_list[5]/feature_landmarks_count[5])\n",
    "            eye = 0 if -5 < zoop < 5 else zoop\n",
    "\n",
    "            # facial_change = pow(5, facial_distance/1000)\n",
    "            facial_change = facial_distance\n",
    "            # eargraph = angle_vertical + angle_horizontal\n",
    "            # eargraph = abs(last_facial_change - current_facial_change)\n",
    "            eargraph = current_facial_change\n",
    "            # eargraph = lip_euclidean\n",
    "            # print(eargraph)\n",
    "            # facial_change = (current_euclidean_distance_list[5]/feature_landmarks_count[5])/80\n",
    "            # eargraph =  2 if euclidean < 0.29 else (if)\n",
    "            # eargraph = current_eye_state\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "#      GRAPHICS on VIDEO STREAM\n",
    "\n",
    "            # lip horizontal-vertial LINE\n",
    "            img = cv2.line(img, (lx1, ly1), (lx2, ly2), (255,0,255), 2)\n",
    "            img = cv2.line(img, (lx3, ly3), (lx4, ly4), (255,0,0), 2)\n",
    "\n",
    "            # eye horizontal-vertial LINE\n",
    "            img = cv2.line(img, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "            img = cv2.line(img, (x3,y3), (x4,y4), (0,0,255), 2)\n",
    "\n",
    "            #screen axes\n",
    "            img = cv2.line(img, (600,0), (600,720), (255,255,255), 1)\n",
    "            img = cv2.line(img, (0,350), (1200,350), (255,255,255), 1)\n",
    "\n",
    "            out_text = \"HEAD MOVED\" if(eye >= 5 or eye <= -5) else \"---%-----\"\n",
    "            cv2.putText(img, out_text, (1000,50), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "            cv2.putText(img, str(\"Lip/Cheek : \"+str(eargraph)), (1000,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "            img = cv2.putText(img, f\"{state_string}\", (1000,80), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "            img = cv2.putText(img, f\"EAR : {euclidean}\", (20, 20), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2 )\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            last_facial_change = current_facial_change\n",
    "            last_landmarks = deepcopy(current_landmarks)\n",
    "\n",
    "            if curr_past % 10 == 0:\n",
    "                last_euclidean_distance_list = deepcopy(current_euclidean_distance_list)\n",
    "            curr_past += 1\n",
    "\n",
    "        else:\n",
    "            # print(\"Result in results.multi_face_landmarks failed. Fail Count : \", fail_count);\n",
    "            fail_count += 1\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    " #     FPS\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        cv2.putText(img, f\"fps: {int(fps)}\", (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 3)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        cv2.imshow(\"image\", img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# i = -1\n",
    "# while True:\n",
    "#     with open(\"data.csv\", 'a') as csv_file:\n",
    "#         csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "#         info = {\"frame\": frame, \"eye\": eye, \"ear\": eargraph, \"facial\": facial_change}\n",
    "#         csv_writer.writerow(info)\n",
    "#\n",
    "#         success, img = cap.read()\n",
    "#\n",
    "#         img = cv2.flip(img, 1)\n",
    "#         img.flags.writeable = False\n",
    "#         imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img_size = img.shape\n",
    "#\n",
    "#         # videoOutput.write(img)\n",
    "#         # allImages.append(img)\n",
    "#         # print(allImages)\n",
    "#\n",
    "#\n",
    "#         results = faceMesh.process(imgRGB)\n",
    "#         img = np.zeros(img.shape, np.uint8)\n",
    "#\n",
    "#         # xcor1, xcor2 = 0, 0\n",
    "#         # ycor1, ycor2 = 0, 0\n",
    "#         # for i in range(54):\n",
    "#         #     img = cv2.line(img, (xcor1, 0), (xcor2, 720), (0,255,0), 1)\n",
    "#         #     img = cv2.line(img, (0, ycor1), (1280, ycor2), (0,255,0), 1)\n",
    "#         #     xcor1 += 25\n",
    "#         #     xcor2 += 25\n",
    "#         #     ycor1 += 25\n",
    "#         #     ycor2 += 25\n",
    "#\n",
    "#         facial_distance = 0\n",
    "#\n",
    "#         if results.multi_face_landmarks:\n",
    "#             l = []\n",
    "#             for faceLms in results.multi_face_landmarks:\n",
    "#                 mpDraw.draw_landmarks(img, faceLms,\n",
    "#                                       mpFaceMesh.FACEMESH_CONTOURS,\n",
    "#                                       landmark_drawing_spec=drawSpecs,\n",
    "#                                       connection_drawing_spec=drawSpecs)\n",
    "#\n",
    "#                 colors = [(0, 0, 0), (255, 255, 255), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0),(0, 0, 0)]\n",
    "#\n",
    "#                 facial_indices = [ind for ind, x in enumerate(faceLms.landmark) if ind not in flat_feature_indices]\n",
    "#                 feature_indices[-1] = set(facial_indices)\n",
    "#\n",
    "#                 # if i == 0:\n",
    "#                 #     print(\"FEATURE INDICES ALL 7\")\n",
    "#                 #     for kkkk in feature_indices:\n",
    "#                 #         print(kkkk)\n",
    "#\n",
    "#\n",
    "#\n",
    "#                 angle_horizontal = 0\n",
    "#                 angle_vertical = 0\n",
    "#\n",
    "#                 # facial_distance = 0\n",
    "#\n",
    "#                 for cid, feature in enumerate(feature_indices):\n",
    "#                     index = 0\n",
    "#                     color_ind = 0\n",
    "#                     # if cid == 2:\n",
    "#                     euclidean_distance = 0\n",
    "#                     point_count = 0\n",
    "#                     for ind, lm in enumerate(faceLms.landmark):\n",
    "#                         if ind in feature:\n",
    "#                             x, y, z = int(img_size[1]*lm.x), int(img_size[0]*lm.y), lm.z\n",
    "#\n",
    "#                             if cid == 6:\n",
    "#                                 img = cv2.circle(img, (x, y), 1, (0, 255, 100), 2)\n",
    "#                                 facial_distance += pow(pow((x-0), 2) + pow((y-450), 2), 1/2)\n",
    "#                                 # img = cv2.line(img, (x,y), (a_oval_landmark[0], a_oval_landmark[1]), (0,0,0), 1)\n",
    "#\n",
    "#                             # if point_count <= 5:\n",
    "#                             euclidean_distance += pow(pow(x, 2) + pow(y, 2), 1/2)\n",
    "#                             # img = cv2.line(img, (0,0), (x,y), (0,0,0), 1)\n",
    "#                             # print(list(feature_indices[5])[1], type(list(feature_indices[5])[0]))\n",
    "#                             # print(\"indices : \",ind, type(ind))\n",
    "#                             # if ind == list(feature_indices[2])[6]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (0,0,0), 10)\n",
    "#                             #     print(\"Black : \"+str(ind))\n",
    "#                             # if ind == list(feature_indices[2])[12]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (255,255,255), 10)\n",
    "#                             #     print(\"White : \"+ str(ind))\n",
    "#                             # if ind == list(feature_indices[2])[24]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (255,0,0), 10)\n",
    "#                             #     print(\"blue : \" + str(ind))\n",
    "#                             # if ind == list(feature_indices[2])[0]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (0,0,255), 10)\n",
    "#                             #     print(\"red : \"+ str(ind))\n",
    "#\n",
    "#                             if ind == list(feature_indices[5])[3] or ind == list(feature_indices[5])[10]:\n",
    "#                                 # if ind == list(feature_indices[5])[3]:\n",
    "#                                 a_oval_landmark = [x, y, z]\n",
    "#                                 img = cv2.circle(img, (x, y), 1, (0, 0, 255), 5)\n",
    "#                                 img = cv2.line(img, (x,y), (600,0), (255,0,0), 2)\n",
    "#                                 img = cv2.line(img, (x,y), (0,350), (0,0,255), 2)\n",
    "#\n",
    "#                                 angle_vertical += pow(pow((x-600), 2) + pow((y-y), 2), 1/2)\n",
    "#                                 angle_horizontal += pow(pow((x-x), 2) + pow((y-350), 2), 1/2)\n",
    "#                             else:\n",
    "#                                 pass\n",
    "#                                 # img = cv2.circle(img, (x, y), 1, colors[1], 2)\n",
    "#\n",
    "#                             if curr_past == 0:\n",
    "#                                 last_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#                             elif curr_past % 1 == 0:\n",
    "#                                 current_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#\n",
    "#\n",
    "#                             index += 1\n",
    "#                             color_ind += 1\n",
    "#                             point_count += 1\n",
    "#\n",
    "#\n",
    "#                 # a_oval_landmark = [feature_indices[5][0] ]\n",
    "#                 # else:\n",
    "#                 #     for ind, lm in enumerate(faceLms.landmark):\n",
    "#                 #         if ind in feature:\n",
    "#                 #             x, y, z = int(img_size[1]*lm.x), int(img_size[0]*lm.y), lm.z\n",
    "#                 #\n",
    "#                 #             img = cv2.circle(img, (x, y), 1, (0,0,255), 3)\n",
    "#                 #             if curr_past == 0:\n",
    "#                 #                 last_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#                 #             elif curr_past % 1 == 0:\n",
    "#                 #                 current_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#                 #             index += 1\n",
    "#                 #             color_ind += 1\n",
    "#\n",
    "#\n",
    "#\n",
    "#             # lips coordinates\n",
    "#             lx1, ly1 = int(faceLms.landmark[61].x*img_size[1]), int(faceLms.landmark[61].y*img_size[0])\n",
    "#             lx2, ly2 = int(faceLms.landmark[291].x*img_size[1]), int(faceLms.landmark[291].y*img_size[0])\n",
    "#             lx3, ly3 = int(faceLms.landmark[0].x*img_size[1]), int(faceLms.landmark[0].y*img_size[0])\n",
    "#             lx4, ly4 = int(faceLms.landmark[17].x*img_size[1]), int(faceLms.landmark[17].y*img_size[0])\n",
    "#\n",
    "#             # left eye coordinates\n",
    "#             x1, y1 = int(faceLms.landmark[133].x*img_size[1]), int(faceLms.landmark[133].y*img_size[0])\n",
    "#             x2, y2 = int(faceLms.landmark[33].x*img_size[1]), int(faceLms.landmark[33].y*img_size[0])\n",
    "#             x4, y4 = int(faceLms.landmark[159].x*img_size[1]), int(faceLms.landmark[159].y*img_size[0])\n",
    "#             x3, y3 = int(faceLms.landmark[145].x*img_size[1]), int(faceLms.landmark[145].y*img_size[0])\n",
    "#\n",
    "#             # lip horizontal-vertial LINE\n",
    "#             img = cv2.line(img, (lx1, ly1), (lx2, ly2), (255,0,255), 2)\n",
    "#             img = cv2.line(img, (lx3, ly3), (lx4, ly4), (255,0,0), 2)\n",
    "#\n",
    "#             # eye horizontal-vertial LINE\n",
    "#             img = cv2.line(img, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "#             img = cv2.line(img, (x3,y3), (x4,y4), (0,0,255), 2)\n",
    "#\n",
    "#             #screen axes\n",
    "#             img = cv2.line(img, (600,0), (600,720), (255,255,255), 1)\n",
    "#             img = cv2.line(img, (0,350), (1200,350), (255,255,255), 1)\n",
    "#\n",
    "#\n",
    "#             # lip euclidean ratio\n",
    "#             lipa, lipb = ear(lx1, ly1, lx2, ly2, lx3, ly3, lx4, ly4)\n",
    "#             lip_euclidean = lipa + lipb\n",
    "#             # eye euclidean ratio\n",
    "#             eyea, eyeb = ear(x1,y1,x2,y2,x3,y3,x4,y4)\n",
    "#             euclidean = eyea/eyeb\n",
    "#\n",
    "#             # print(x1,y1,x2,y2,x3,y3,x4,y4)\n",
    "#             #full=1 flinch=2, half=3, closed=4\n",
    "#             #full=2 half=1 closed=0\n",
    "#\n",
    "#             if curr_past == 0:\n",
    "#                 last_euclidean_distance_list[cid] = euclidean_distance\n",
    "#                 last_facial_change = lip_euclidean\n",
    "#             else:\n",
    "#                 current_euclidean_distance_list[cid] = euclidean_distance\n",
    "#                 current_facial_change = lip_euclidean\n",
    "#\n",
    "#\n",
    "#             if euclidean > 0.29 and (current_eye_state == 0 or current_eye_state == 1):#fully open\n",
    "#                 blink_count += 1\n",
    "#                 current_eye_state = 2\n",
    "#                 state_string = \"FULL OPEN\"\n",
    "#             elif euclidean < 0.15 and (current_eye_state == 2 or current_eye_state == 1):\n",
    "#                 blink_count += 1\n",
    "#                 current_eye_state = 0\n",
    "#                 state_string = \"FULL CLOSED\"\n",
    "#             elif 0.18 <= euclidean < 0.29 and (current_eye_state == 0 or current_eye_state == 2):\n",
    "#                 blink_count += 1\n",
    "#                 current_eye_state = 1\n",
    "#                 state_string = \"HALF OPEN/CLOSED\"\n",
    "#\n",
    "#             img = cv2.putText(img, f\"{state_string}\", (1000,80), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "#\n",
    "#             img = cv2.putText(img, f\"EAR : {euclidean}\", (20, 20), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2 )\n",
    "#\n",
    "#\n",
    "#             for i in range(7):\n",
    "#                 # diff_list[i] = (sum((abs(last_landmarks-current_landmarks))[i]))/feature_landmarks_count[i]\n",
    "#                 # if i == 2:\n",
    "#                 # pass\n",
    "#                 diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))/feature_landmarks_count[i]\n",
    "#                 # diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))\n",
    "#\n",
    "#             frame = curr_past #current past frame\n",
    "#             # eye = diff_list[0] if diff_list[0] > 1 else 1\n",
    "#             zoop = (current_euclidean_distance_list[5]/feature_landmarks_count[5]) - (last_euclidean_distance_list[5]/feature_landmarks_count[5])\n",
    "#             # eye = 0 if -5 < zoop < 5 else zoop\n",
    "#             eye = 0\n",
    "#             # facial_change = pow(5, facial_distance/1000)\n",
    "#             facial_change = facial_distance\n",
    "#             # eargraph = angle_vertical + angle_horizontal\n",
    "#             eargraph = abs(last_facial_change - current_facial_change)\n",
    "#             # eargraph = lip_euclidean\n",
    "#             # print(eargraph)\n",
    "#             # facial_change = (current_euclidean_distance_list[5]/feature_landmarks_count[5])/80\n",
    "#             # eargraph =  2 if euclidean < 0.29 else (if)\n",
    "#             # eargraph = current_eye_state\n",
    "#\n",
    "#             out_text = \"HEAD MOVED\" if(eye >= 5 or eye <= -5) else \"---------\"\n",
    "#             cv2.putText(img, out_text, (1000,50), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "#             cv2.putText(img, str(\"Lip/Cheek : \"+str(eargraph)), (1000,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "#\n",
    "#             last_facial_change = current_facial_change\n",
    "#             last_landmarks = deepcopy(current_landmarks)\n",
    "#\n",
    "#             if curr_past % 10 == 0:\n",
    "#                 last_euclidean_distance_list = deepcopy(current_euclidean_distance_list)\n",
    "#             curr_past += 1\n",
    "#\n",
    "#         else:\n",
    "#             # print(\"Result in results.multi_face_landmarks failed. Fail Count : \", fail_count);\n",
    "#             fail_count += 1\n",
    "#         cTime = time.time()\n",
    "#         fps = 1 / (cTime - pTime)\n",
    "#         pTime = cTime\n",
    "#         cv2.putText(img, f\"fps: {int(fps)}\", (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 3)\n",
    "#         cv2.imshow(\"image\", img)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "#             break\n",
    "#\n",
    "#\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T15:40:15.180103800Z",
     "start_time": "2023-07-22T15:40:15.172131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
