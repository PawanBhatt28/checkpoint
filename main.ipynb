{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-28T09:15:37.129239800Z",
     "start_time": "2023-07-28T09:15:33.602077600Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(1, 1, 1)\n",
    "eye_diff_list = []\n",
    "xx = []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap2 = cv2.VideoCapture(1)\n",
    "width=1920\n",
    "height = 1080\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "pTime = 0\n",
    "\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "drawSpecs = mpDraw.DrawingSpec(thickness=1, circle_radius=1)\n",
    "faceMesh = mpFaceMesh.FaceMesh(\n",
    "    static_image_mode = False,\n",
    "    max_num_faces = 1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.45,\n",
    "    min_tracking_confidence = 0.45   # Will we miss a lot of information with higher confidence threshold??\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T09:05:44.454819200Z",
     "start_time": "2023-07-28T09:05:32.943849400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def ear(x1, y1, x2, y2, x3, y3, x4, y4):\n",
    "    a = math.sqrt(math.pow((x2-x1), 2) + math.pow((y2-y1), 2))\n",
    "    b = math.sqrt(math.pow((x4-x3), 2) + math.pow((y4-y3), 2))\n",
    "    return b,a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T08:44:01.043428500Z",
     "start_time": "2023-07-28T08:44:01.033322100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_face(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)\n",
    "    try:\n",
    "        x,y,w,h = faces[0]\n",
    "        image = image[y:y+w+100, x:x+h+100]\n",
    "    except:\n",
    "        print(\"face not found\")\n",
    "    return image\n",
    "\n",
    "# for (x,y,w,h) in faces:\n",
    "    #     cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,0), 2)\n",
    "    #     cropped_image = crop_image(img, x, y, w, h)\n",
    "    #     cv2.imshow(cropped_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T08:44:01.063659100Z",
     "start_time": "2023-07-28T08:44:01.053451100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 179\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;66;03m# img = cv2.line(img, (x,y), (600,0), (0,255,0), 2)\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;66;03m# img = cv2.line(img, (x,y), (0,350), (255,255,1), 2)\u001B[39;00m\n\u001B[0;32m    178\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mline(img, (x,y), (\u001B[38;5;241m20\u001B[39m,y), (\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m255\u001B[39m,\u001B[38;5;241m255\u001B[39m), \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m--> 179\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m255\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcircle(img, (x, y), \u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m    183\u001B[0m angle_horizontal \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mpow\u001B[39m(\u001B[38;5;28mpow\u001B[39m((x\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m20\u001B[39m), \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mpow\u001B[39m((y\u001B[38;5;241m-\u001B[39my), \u001B[38;5;241m2\u001B[39m), \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# # we can n dimensional numpy array with indxes wise alternate to features\n",
    "# n-dimensional numpy array, with each feature corresponding to each row.\n",
    "# as each feature has different number of landmarks, so dtype=object( learn it)\n",
    "# feature_indices = np.array([list(), list(), list(), list(), list(), list()], dtype=object);\n",
    "\n",
    "feature_indices = [set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set(),\n",
    "                   set()]\n",
    "\n",
    "# LIST - feature_indices = [ [] [] [] [] [] [] ]\n",
    "for s, t in mpFaceMesh.FACEMESH_RIGHT_EYE:          # right eye      0\n",
    "    feature_indices[0].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_LEFT_EYE:           # left eye       1\n",
    "    feature_indices[1].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_LIPS:               # lips           2\n",
    "    feature_indices[2].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_RIGHT_EYEBROW:      # right eyebrow  3\n",
    "    feature_indices[3].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_LEFT_EYEBROW:       # left eyebrow   4\n",
    "    feature_indices[4].update([s, t])\n",
    "for s, t in mpFaceMesh.FACEMESH_FACE_OVAL:          # oval           5\n",
    "    feature_indices[5].update([s, t])\n",
    "\n",
    "flat_feature_indices = [ j for i in feature_indices for j in i]\n",
    "# facial_indices = []\n",
    "\n",
    "le, re, lip, reb, leb, oval = len(feature_indices[0]), len(feature_indices[1]), len(feature_indices[2]), len(feature_indices[3]), len(feature_indices[4]),len(feature_indices[5])\n",
    "facial = 478 - le + re + lip + reb + oval\n",
    "feature_landmarks_count = [le, re, lip, reb, leb, oval, facial]\n",
    "\n",
    "current_landmarks = np.array([np.zeros(feature_landmarks_count[0]),\n",
    "                     np.zeros(feature_landmarks_count[1]),\n",
    "                     np.zeros(feature_landmarks_count[2]),\n",
    "                     np.zeros(feature_landmarks_count[3]),\n",
    "                     np.zeros(feature_landmarks_count[4]),\n",
    "                     np.zeros(feature_landmarks_count[5]),\n",
    "                     np.zeros(feature_landmarks_count[6])], dtype=object)\n",
    "# current_landmarks = np.array(current_landmarks, dtype=object)\n",
    "last_landmarks = np.array(np.copy(current_landmarks))\n",
    "\n",
    "cl = [0]*len(feature_indices[0])\n",
    "ll = [0]*len(feature_indices[0])\n",
    "\n",
    "curr_past = 0\n",
    "diff = 0\n",
    "fail_count = 0\n",
    "change_detected_count = 0\n",
    "\n",
    "current_landmark_list = np.array([0 for i in range(478)])\n",
    "last_landmark_list = np.array([0 for i in range(478)])\n",
    "\n",
    "diff_list = [0] * 7\n",
    "euclidean_distance_list = [0] * 7\n",
    "\n",
    "last_euclidean_distance_list = [0] * 8\n",
    "current_euclidean_distance_list = [0] * 8\n",
    "\n",
    "eye_diff_list = []\n",
    "\n",
    "current_facial_change = 0\n",
    "last_facial_change = 0\n",
    "\n",
    "\n",
    "blink_count = 0\n",
    "current_eye_state = 2\n",
    "\n",
    "\n",
    "# allImages = []\n",
    "# videoOutput = cv2.VideoWriter(\"eyeVideo.avi\", cv2.VideoWriter_fourcc(*'XVID'), 10, (640, 480))\n",
    "eye_diff_list = []\n",
    "xx = []\n",
    "\n",
    "# print(\"Current Landmarks : \", current_landmarks.shape)\n",
    "# print(\"Last Landmarks : \", last_landmarks.shape)\n",
    "# print(\"Feature indices : \", feature_indices)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#       CSV DATA FILE OPENING\n",
    "\n",
    "field_names = [\"time\", \"left_eye\", \"right_eye\",\"lips\",\"head_h\", \"head_v\", \"head_slope\"]\n",
    "state_string = \"Open\"\n",
    "frame, e1, e2, l1, hh, hv, hslope = 1,0,0,0,0,0,0\n",
    "# frame, eye, eargraph, facial_change = 1,1,0,0\n",
    "with open('data.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "    csv_writer.writeheader()\n",
    "    info = {\"time\": frame, \"left_eye\": e1, \"right_eye\": e2, \"lips\": l1,  \"head_h\": hh, \"head_v\" : hv, \"head_slope\": hslope}\n",
    "    csv_writer.writerow(info)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "i = -1\n",
    "count = 0\n",
    "while True:\n",
    "    with open(\"data.csv\", 'a') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        info = {\"time\": frame, \"left_eye\": e1, \"right_eye\": e2, \"lips\": l1,  \"head_h\": hh, \"head_v\": hv, \"head_slope\": hslope}\n",
    "        csv_writer.writerow(info)\n",
    "\n",
    "    success, img = cap.read()\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    # cropped_image = get_face(img)\n",
    "    # cv2.imshow(\"\",cropped_image)\n",
    "    # img = cropped_image\n",
    "\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # img = imgRGB\n",
    "    # kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    # img = cv2.filter2D(img, -1, kernel)\n",
    "    # cv2.imshow(\"sad\",img)\n",
    "\n",
    "    img.flags.writeable = False\n",
    "    # try:\n",
    "    #     mp_get_face(img)\n",
    "    # except:\n",
    "    #     count += 1\n",
    "    #     print(\"face not found : \", count)\n",
    "    imgRGB = img\n",
    "    # img = imgRGB\n",
    "\n",
    "    img_size = img.shape\n",
    "\n",
    "    results = faceMesh.process(imgRGB)\n",
    "    # img = np.zeros(img.shape, np.uint8)\n",
    "\n",
    "    facial_distance = 0\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        l = []\n",
    "        for faceLms in results.multi_face_landmarks:\n",
    "            # mpDraw.draw_landmarks(img, faceLms,\n",
    "            #                       mpFaceMesh.FACEMESH_CONTOURS,\n",
    "            #                       landmark_drawing_spec=drawSpecs,\n",
    "            #                       connection_drawing_spec=drawSpecs)\n",
    "\n",
    "            colors = [(0, 0, 0), (255, 255, 255), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0),(0, 0, 0)]\n",
    "\n",
    "            facial_indices = [ind for ind, x in enumerate(faceLms.landmark) if ind not in flat_feature_indices]\n",
    "            feature_indices[-1] = set(facial_indices)\n",
    "\n",
    "            angle_horizontal = 0\n",
    "            angle_vertical = 0\n",
    "\n",
    "            # facial_distance = 0\n",
    "\n",
    "            for cid, feature in enumerate(feature_indices):\n",
    "                index = 0\n",
    "                color_ind = 0\n",
    "                # if cid == 2:\n",
    "                euclidean_distance = 0\n",
    "                point_count = 0\n",
    "                for ind, lm in enumerate(faceLms.landmark):\n",
    "                    if ind in feature:\n",
    "                        # Coordinaated of every LANDMARK on FACE with origin\n",
    "                        x, y, z = int(img_size[1]*lm.x), int(img_size[0]*lm.y), lm.z\n",
    "\n",
    "                        if cid == 6:\n",
    "                            # img = cv2.circle(img, (x, y), 1, (0, 255, 100), 2)\n",
    "                            facial_distance += pow(pow((x-0), 2) + pow((y-450), 2), 1/2)\n",
    "                            # img = cv2.line(img, (x,y), (a_oval_landmark[0], a_oval_landmark[1]), (0,0,0), 1)\n",
    "\n",
    "                        # SUM DISTANACE of evey LANDMARK on FACE with origin\n",
    "                        euclidean_distance += pow(pow(x, 2) + pow(y, 2), 1/2)\n",
    "                        # img = cv2.line(img, (0,0), (x,y), (255,255,0), 1)\n",
    "\n",
    "                        # POINTS in middle of FACE to CALCUALTE the VERTICAL/HORIZONTAL movement\n",
    "                        if ind == list(feature_indices[5])[3] or ind == list(feature_indices[5])[10]:\n",
    "                            a_oval_landmark = [x, y, z]\n",
    "                            # img = cv2.line(img, (x,y), (600,0), (0,255,0), 2)\n",
    "                            # img = cv2.line(img, (x,y), (0,350), (255,255,1), 2)\n",
    "\n",
    "                            img = cv2.line(img, (x,y), (20,y), (0,255,255), 2)\n",
    "                            img = cv2.line(img, (x,y), (x,20), (255,0,150), 2)\n",
    "\n",
    "                            img = cv2.circle(img, (x, y), 1, (0, 0, 255), 5)\n",
    "\n",
    "                            angle_horizontal += pow(pow((x-20), 2) + pow((y-y), 2), 1/2)\n",
    "                            angle_vertical += pow(pow((x-x), 2) + pow((y-20), 2), 1/2)\n",
    "\n",
    "\n",
    "                        if curr_past == 0:\n",
    "                            last_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "                        elif curr_past % 1 == 0:\n",
    "                            current_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "\n",
    "\n",
    "                        index += 1\n",
    "                        color_ind += 1\n",
    "                        point_count += 1\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      COORDINATES EXTRACTION\n",
    "        # LIPS\n",
    "        # Coordinates\n",
    "        lx1, ly1 = int(faceLms.landmark[61].x*img_size[1]), int(faceLms.landmark[61].y*img_size[0])\n",
    "        lx2, ly2 = int(faceLms.landmark[291].x*img_size[1]), int(faceLms.landmark[291].y*img_size[0])\n",
    "        lx3, ly3 = int(faceLms.landmark[0].x*img_size[1]), int(faceLms.landmark[0].y*img_size[0])\n",
    "        lx4, ly4 = int(faceLms.landmark[17].x*img_size[1]), int(faceLms.landmark[17].y*img_size[0])\n",
    "\n",
    "        # euclidean aspect ratio\n",
    "        lipa, lipb = ear(lx1, ly1, lx2, ly2, lx3, ly3, lx4, ly4)\n",
    "        lip_euclidean = lipa / lipb\n",
    "\n",
    "        # LEFT EYE\n",
    "        # Coordinates\n",
    "        x1, y1 = int(faceLms.landmark[133].x*img_size[1]), int(faceLms.landmark[133].y*img_size[0])\n",
    "        x2, y2 = int(faceLms.landmark[33].x*img_size[1]), int(faceLms.landmark[33].y*img_size[0])\n",
    "        x4, y4 = int(faceLms.landmark[159].x*img_size[1]), int(faceLms.landmark[159].y*img_size[0])\n",
    "        x3, y3 = int(faceLms.landmark[145].x*img_size[1]), int(faceLms.landmark[145].y*img_size[0])\n",
    "\n",
    "        # euclidean aspect ratio\n",
    "        eyea, eyeb = ear(x1,y1,x2,y2,x3,y3,x4,y4)\n",
    "        eye_euclidean = eyea/eyeb\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      LAST CURRENT UPDATION\n",
    "\n",
    "        # INCREASING the WEIGHT of VERTIAL MOVEMENT (because vertial motion is not as much as horizontal change)\n",
    "        # angle_vertical = angle_vertical * 3\n",
    "        if curr_past == 0:\n",
    "            last_euclidean_distance_list[cid] = euclidean_distance\n",
    "            last_facial_change = angle_vertical + angle_horizontal\n",
    "        else:\n",
    "            current_euclidean_distance_list[cid] = euclidean_distance\n",
    "            current_facial_change = angle_vertical + angle_horizontal\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      DISTANCES CALCULATION for GRAPH\n",
    "\n",
    "        for i in range(7):\n",
    "            # diff_list[i] = (sum((abs(last_landmarks-current_landmarks))[i]))/feature_landmarks_count[i]\n",
    "            diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))/feature_landmarks_count[i]\n",
    "            # diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))\n",
    "\n",
    "        # calculating time passing for graph\n",
    "        frame = curr_past\n",
    "\n",
    "        e1 = eye_euclidean\n",
    "        e2 = 0\n",
    "\n",
    "        l1 = lip_euclidean\n",
    "\n",
    "        hh = angle_horizontal\n",
    "        hv = angle_vertical\n",
    "\n",
    "        hslope = 0 if abs(last_facial_change - current_facial_change) < 7 else 10\n",
    "        '''\n",
    "                INCREASING the WEIGHT of VERTIAL MOVEMENT (because vertial motion is not as much as horizontal change)\n",
    "                2. If the face is parallely aligned with the camera then the detection is very goood.\n",
    "                   else if the face is at an angle with the camera, titled backward or forward(resting position) then detections are not acurate as in parallel.\n",
    "                FALSE\n",
    "                    -I had my method of calcualtion incorrect, now Coordinates are changed which calculate vertical&horizontal motion unbiased.\n",
    "        '''\n",
    "\n",
    "\n",
    "        # zoop = (current_euclidean_distance_list[5]/feature_landmarks_count[5]) - (last_euclidean_distance_list[5]/feature_landmarks_count[5])\n",
    "        # eye = diff_list[0] if diff_list[0] > 1 else 1\n",
    "        # facial_change = pow(5, facial_distance/1000)\n",
    "        # facial_change = facial_distance\n",
    "        # eargraph = angle_vertical + angle_horizontal\n",
    "        # eargraph = abs(last_facial_change - current_facial_change)\n",
    "        # eargraph = current_facial_change\n",
    "        # eargraph = lip_euclidean\n",
    "        # print(eargraph)\n",
    "        # facial_change = (current_euclidean_distance_list[5]/feature_landmarks_count[5])/80\n",
    "        # eargraph =  2 if euclidean < 0.29 else (if)\n",
    "        # eargraph = current_eye_state\n",
    "\n",
    "        #------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        #      STATE OF EYE\n",
    "        if eye_euclidean > 0.29 and (current_eye_state == 0 or current_eye_state == 1):#fully open\n",
    "            blink_count += 1\n",
    "            current_eye_state = 2\n",
    "            state_string = \"FULL OPEN\"\n",
    "        elif eye_euclidean < 0.15 and (current_eye_state == 2 or current_eye_state == 1):\n",
    "            blink_count += 1\n",
    "            current_eye_state = 0\n",
    "            state_string = \"FULL CLOSED\"\n",
    "        elif 0.18 <= eye_euclidean < 0.29 and (current_eye_state == 0 or current_eye_state == 2):\n",
    "            blink_count += 1\n",
    "            current_eye_state = 1\n",
    "            state_string = \"HALF OPEN/CLOSED\"\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#      GRAPHICS on VIDEO STREAM\n",
    "\n",
    "        # lip horizontal-vertial LINE\n",
    "        img = cv2.line(img, (lx1, ly1), (lx2, ly2), (255,0,255), 2)\n",
    "        img = cv2.line(img, (lx3, ly3), (lx4, ly4), (255,0,0), 2)\n",
    "\n",
    "        # eye horizontal-vertial LINE\n",
    "        img = cv2.line(img, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "        img = cv2.line(img, (x3,y3), (x4,y4), (0,0,255), 2)\n",
    "\n",
    "        #screen axes\n",
    "        img = cv2.line(img, (20,0), (20,720), (255,255,255), 1)\n",
    "        img = cv2.line(img, (0,20), (1200,20), (255,255,255), 1)\n",
    "\n",
    "\n",
    "        out_text = \"Head Moved\" if(hslope) else \"\"\n",
    "        cv2.putText(img, out_text, (1000,50), cv2.FONT_HERSHEY_PLAIN, 2, (70,150,255), 2)\n",
    "        cv2.putText(img, str(\"Lip Ratio: \"+str(lip_euclidean)), (1000,115), cv2.FONT_HERSHEY_PLAIN, 2, (180,59,110), 2)\n",
    "        img = cv2.putText(img, f\"{state_string}\", (1000,85), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,0), 2)\n",
    "        img = cv2.putText(img, f\"eye ratio : {eye_euclidean}\", (20, 20), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2 )\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        last_facial_change = current_facial_change\n",
    "        last_landmarks = deepcopy(current_landmarks)\n",
    "\n",
    "        if curr_past % 10 == 0:\n",
    "            last_euclidean_distance_list = deepcopy(current_euclidean_distance_list)\n",
    "\n",
    "        curr_past += 1\n",
    "\n",
    "    else:\n",
    "        # print(\"Result in results.multi_face_landmarks failed. Fail Count : \", fail_count);\n",
    "        fail_count += 1\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "#     FPS\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    cv2.putText(img, f\"fps: {int(fps)}\", (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 3)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    cv2.imshow(\"image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T08:56:34.317288300Z",
     "start_time": "2023-07-28T08:47:39.985604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "  def mp_get_face(image):\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.3)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    result = face_detection.process(image)\n",
    "\n",
    "    if result.detections:\n",
    "        for detection in result.detections:\n",
    "            mp_drawing.draw_detection(image, detection)\n",
    "        # for fn, face in enumerate(result.detections):\n",
    "        #     face_data = face.location_data\n",
    "        #     # print(\"Confidene : \", round(face.score[0], 2))\n",
    "        #     # print(\"Face Bounding Box : \", face_data.relative_bounding_box)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "    cv2.imshow(\"stream\", image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T09:07:49.449937500Z",
     "start_time": "2023-07-28T09:07:49.429457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image =  cap.read()\n",
    "    image.flags.writeable = False\n",
    "    cv2.imshow(\"first\", image)\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.3)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = face_detection.process(image)\n",
    "\n",
    "    if result.detections:\n",
    "        for detection in result.detections:\n",
    "            mp_drawing.draw_detection(image, detection)\n",
    "        # for fn, face in enumerate(result.detections):\n",
    "        #     face_data = face.location_data\n",
    "        #     # print(\"Confidene : \", round(face.score[0], 2))\n",
    "        #     # print(\"Face Bounding Box : \", face_data.relative_bounding_box)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "    cv2.imshow(\"stream\", image)\n",
    "    print(\"working\")\n",
    "    # cv2.imshow(\"ada\", img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-28T09:20:28.634501200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# i = -1\n",
    "# while True:\n",
    "#     with open(\"data.csv\", 'a') as csv_file:\n",
    "#         csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "#         info = {\"frame\": frame, \"eye\": eye, \"ear\": eargraph, \"facial\": facial_change}\n",
    "#         csv_writer.writerow(info)\n",
    "#\n",
    "#         success, img = cap.read()\n",
    "#\n",
    "#         img = cv2.flip(img, 1)\n",
    "#         img.flags.writeable = False\n",
    "#         imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img_size = img.shape\n",
    "#\n",
    "#         # videoOutput.write(img)\n",
    "#         # allImages.append(img)\n",
    "#         # print(allImages)\n",
    "#\n",
    "#\n",
    "#         results = faceMesh.process(imgRGB)\n",
    "#         img = np.zeros(img.shape, np.uint8)\n",
    "#\n",
    "#         # xcor1, xcor2 = 0, 0\n",
    "#         # ycor1, ycor2 = 0, 0\n",
    "#         # for i in range(54):\n",
    "#         #     img = cv2.line(img, (xcor1, 0), (xcor2, 720), (0,255,0), 1)\n",
    "#         #     img = cv2.line(img, (0, ycor1), (1280, ycor2), (0,255,0), 1)\n",
    "#         #     xcor1 += 25\n",
    "#         #     xcor2 += 25\n",
    "#         #     ycor1 += 25\n",
    "#         #     ycor2 += 25\n",
    "#\n",
    "#         facial_distance = 0\n",
    "#\n",
    "#         if results.multi_face_landmarks:\n",
    "#             l = []\n",
    "#             for faceLms in results.multi_face_landmarks:\n",
    "#                 mpDraw.draw_landmarks(img, faceLms,\n",
    "#                                       mpFaceMesh.FACEMESH_CONTOURS,\n",
    "#                                       landmark_drawing_spec=drawSpecs,\n",
    "#                                       connection_drawing_spec=drawSpecs)\n",
    "#\n",
    "#                 colors = [(0, 0, 0), (255, 255, 255), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0),(0, 0, 0)]\n",
    "#\n",
    "#                 facial_indices = [ind for ind, x in enumerate(faceLms.landmark) if ind not in flat_feature_indices]\n",
    "#                 feature_indices[-1] = set(facial_indices)\n",
    "#\n",
    "#                 # if i == 0:\n",
    "#                 #     print(\"FEATURE INDICES ALL 7\")\n",
    "#                 #     for kkkk in feature_indices:\n",
    "#                 #         print(kkkk)\n",
    "#\n",
    "#\n",
    "#\n",
    "#                 angle_horizontal = 0\n",
    "#                 angle_vertical = 0\n",
    "#\n",
    "#                 # facial_distance = 0\n",
    "#\n",
    "#                 for cid, feature in enumerate(feature_indices):\n",
    "#                     index = 0\n",
    "#                     color_ind = 0\n",
    "#                     # if cid == 2:\n",
    "#                     euclidean_distance = 0\n",
    "#                     point_count = 0\n",
    "#                     for ind, lm in enumerate(faceLms.landmark):\n",
    "#                         if ind in feature:\n",
    "#                             x, y, z = int(img_size[1]*lm.x), int(img_size[0]*lm.y), lm.z\n",
    "#\n",
    "#                             if cid == 6:\n",
    "#                                 img = cv2.circle(img, (x, y), 1, (0, 255, 100), 2)\n",
    "#                                 facial_distance += pow(pow((x-0), 2) + pow((y-450), 2), 1/2)\n",
    "#                                 # img = cv2.line(img, (x,y), (a_oval_landmark[0], a_oval_landmark[1]), (0,0,0), 1)\n",
    "#\n",
    "#                             # if point_count <= 5:\n",
    "#                             euclidean_distance += pow(pow(x, 2) + pow(y, 2), 1/2)\n",
    "#                             # img = cv2.line(img, (0,0), (x,y), (0,0,0), 1)\n",
    "#                             # print(list(feature_indices[5])[1], type(list(feature_indices[5])[0]))\n",
    "#                             # print(\"indices : \",ind, type(ind))\n",
    "#                             # if ind == list(feature_indices[2])[6]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (0,0,0), 10)\n",
    "#                             #     print(\"Black : \"+str(ind))\n",
    "#                             # if ind == list(feature_indices[2])[12]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (255,255,255), 10)\n",
    "#                             #     print(\"White : \"+ str(ind))\n",
    "#                             # if ind == list(feature_indices[2])[24]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (255,0,0), 10)\n",
    "#                             #     print(\"blue : \" + str(ind))\n",
    "#                             # if ind == list(feature_indices[2])[0]:\n",
    "#                             #     img = cv2.circle(img, (x, y), 1, (0,0,255), 10)\n",
    "#                             #     print(\"red : \"+ str(ind))\n",
    "#\n",
    "#                             if ind == list(feature_indices[5])[3] or ind == list(feature_indices[5])[10]:\n",
    "#                                 # if ind == list(feature_indices[5])[3]:\n",
    "#                                 a_oval_landmark = [x, y, z]\n",
    "#                                 img = cv2.circle(img, (x, y), 1, (0, 0, 255), 5)\n",
    "#                                 img = cv2.line(img, (x,y), (600,0), (255,0,0), 2)\n",
    "#                                 img = cv2.line(img, (x,y), (0,350), (0,0,255), 2)\n",
    "#\n",
    "#                                 angle_vertical += pow(pow((x-600), 2) + pow((y-y), 2), 1/2)\n",
    "#                                 angle_horizontal += pow(pow((x-x), 2) + pow((y-350), 2), 1/2)\n",
    "#                             else:\n",
    "#                                 pass\n",
    "#                                 # img = cv2.circle(img, (x, y), 1, colors[1], 2)\n",
    "#\n",
    "#                             if curr_past == 0:\n",
    "#                                 last_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#                             elif curr_past % 1 == 0:\n",
    "#                                 current_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#\n",
    "#\n",
    "#                             index += 1\n",
    "#                             color_ind += 1\n",
    "#                             point_count += 1\n",
    "#\n",
    "#\n",
    "#                 # a_oval_landmark = [feature_indices[5][0] ]\n",
    "#                 # else:\n",
    "#                 #     for ind, lm in enumerate(faceLms.landmark):\n",
    "#                 #         if ind in feature:\n",
    "#                 #             x, y, z = int(img_size[1]*lm.x), int(img_size[0]*lm.y), lm.z\n",
    "#                 #\n",
    "#                 #             img = cv2.circle(img, (x, y), 1, (0,0,255), 3)\n",
    "#                 #             if curr_past == 0:\n",
    "#                 #                 last_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#                 #             elif curr_past % 1 == 0:\n",
    "#                 #                 current_landmarks[cid][index] = abs(x) + abs(y) + abs(z)\n",
    "#                 #             index += 1\n",
    "#                 #             color_ind += 1\n",
    "#\n",
    "#\n",
    "#\n",
    "#             # lips coordinates\n",
    "#             lx1, ly1 = int(faceLms.landmark[61].x*img_size[1]), int(faceLms.landmark[61].y*img_size[0])\n",
    "#             lx2, ly2 = int(faceLms.landmark[291].x*img_size[1]), int(faceLms.landmark[291].y*img_size[0])\n",
    "#             lx3, ly3 = int(faceLms.landmark[0].x*img_size[1]), int(faceLms.landmark[0].y*img_size[0])\n",
    "#             lx4, ly4 = int(faceLms.landmark[17].x*img_size[1]), int(faceLms.landmark[17].y*img_size[0])\n",
    "#\n",
    "#             # left eye coordinates\n",
    "#             x1, y1 = int(faceLms.landmark[133].x*img_size[1]), int(faceLms.landmark[133].y*img_size[0])\n",
    "#             x2, y2 = int(faceLms.landmark[33].x*img_size[1]), int(faceLms.landmark[33].y*img_size[0])\n",
    "#             x4, y4 = int(faceLms.landmark[159].x*img_size[1]), int(faceLms.landmark[159].y*img_size[0])\n",
    "#             x3, y3 = int(faceLms.landmark[145].x*img_size[1]), int(faceLms.landmark[145].y*img_size[0])\n",
    "#\n",
    "#             # lip horizontal-vertial LINE\n",
    "#             img = cv2.line(img, (lx1, ly1), (lx2, ly2), (255,0,255), 2)\n",
    "#             img = cv2.line(img, (lx3, ly3), (lx4, ly4), (255,0,0), 2)\n",
    "#\n",
    "#             # eye horizontal-vertial LINE\n",
    "#             img = cv2.line(img, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "#             img = cv2.line(img, (x3,y3), (x4,y4), (0,0,255), 2)\n",
    "#\n",
    "#             #screen axes\n",
    "#             img = cv2.line(img, (600,0), (600,720), (255,255,255), 1)\n",
    "#             img = cv2.line(img, (0,350), (1200,350), (255,255,255), 1)\n",
    "#\n",
    "#\n",
    "#             # lip euclidean ratio\n",
    "#             lipa, lipb = ear(lx1, ly1, lx2, ly2, lx3, ly3, lx4, ly4)\n",
    "#             lip_euclidean = lipa + lipb\n",
    "#             # eye euclidean ratio\n",
    "#             eyea, eyeb = ear(x1,y1,x2,y2,x3,y3,x4,y4)\n",
    "#             euclidean = eyea/eyeb\n",
    "#\n",
    "#             # print(x1,y1,x2,y2,x3,y3,x4,y4)\n",
    "#             #full=1 flinch=2, half=3, closed=4\n",
    "#             #full=2 half=1 closed=0\n",
    "#\n",
    "#             if curr_past == 0:\n",
    "#                 last_euclidean_distance_list[cid] = euclidean_distance\n",
    "#                 last_facial_change = lip_euclidean\n",
    "#             else:\n",
    "#                 current_euclidean_distance_list[cid] = euclidean_distance\n",
    "#                 current_facial_change = lip_euclidean\n",
    "#\n",
    "#\n",
    "#             if euclidean > 0.29 and (current_eye_state == 0 or current_eye_state == 1):#fully open\n",
    "#                 blink_count += 1\n",
    "#                 current_eye_state = 2\n",
    "#                 state_string = \"FULL OPEN\"\n",
    "#             elif euclidean < 0.15 and (current_eye_state == 2 or current_eye_state == 1):\n",
    "#                 blink_count += 1\n",
    "#                 current_eye_state = 0\n",
    "#                 state_string = \"FULL CLOSED\"\n",
    "#             elif 0.18 <= euclidean < 0.29 and (current_eye_state == 0 or current_eye_state == 2):\n",
    "#                 blink_count += 1\n",
    "#                 current_eye_state = 1\n",
    "#                 state_string = \"HALF OPEN/CLOSED\"\n",
    "#\n",
    "#             img = cv2.putText(img, f\"{state_string}\", (1000,80), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "#\n",
    "#             img = cv2.putText(img, f\"EAR : {euclidean}\", (20, 20), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2 )\n",
    "#\n",
    "#\n",
    "#             for i in range(7):\n",
    "#                 # diff_list[i] = (sum((abs(last_landmarks-current_landmarks))[i]))/feature_landmarks_count[i]\n",
    "#                 # if i == 2:\n",
    "#                 # pass\n",
    "#                 diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))/feature_landmarks_count[i]\n",
    "#                 # diff_list[i] = (sum((np.power(abs(last_landmarks-current_landmarks), 1))[i]))\n",
    "#\n",
    "#             frame = curr_past #current past frame\n",
    "#             # eye = diff_list[0] if diff_list[0] > 1 else 1\n",
    "#             zoop = (current_euclidean_distance_list[5]/feature_landmarks_count[5]) - (last_euclidean_distance_list[5]/feature_landmarks_count[5])\n",
    "#             # eye = 0 if -5 < zoop < 5 else zoop\n",
    "#             eye = 0\n",
    "#             # facial_change = pow(5, facial_distance/1000)\n",
    "#             facial_change = facial_distance\n",
    "#             # eargraph = angle_vertical + angle_horizontal\n",
    "#             eargraph = abs(last_facial_change - current_facial_change)\n",
    "#             # eargraph = lip_euclidean\n",
    "#             # print(eargraph)\n",
    "#             # facial_change = (current_euclidean_distance_list[5]/feature_landmarks_count[5])/80\n",
    "#             # eargraph =  2 if euclidean < 0.29 else (if)\n",
    "#             # eargraph = current_eye_state\n",
    "#\n",
    "#             out_text = \"HEAD MOVED\" if(eye >= 5 or eye <= -5) else \"---------\"\n",
    "#             cv2.putText(img, out_text, (1000,50), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "#             cv2.putText(img, str(\"Lip/Cheek : \"+str(eargraph)), (1000,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "#\n",
    "#             last_facial_change = current_facial_change\n",
    "#             last_landmarks = deepcopy(current_landmarks)\n",
    "#\n",
    "#             if curr_past % 10 == 0:\n",
    "#                 last_euclidean_distance_list = deepcopy(current_euclidean_distance_list)\n",
    "#             curr_past += 1\n",
    "#\n",
    "#         else:\n",
    "#             # print(\"Result in results.multi_face_landmarks failed. Fail Count : \", fail_count);\n",
    "#             fail_count += 1\n",
    "#         cTime = time.time()\n",
    "#         fps = 1 / (cTime - pTime)\n",
    "#         pTime = cTime\n",
    "#         cv2.putText(img, f\"fps: {int(fps)}\", (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 3)\n",
    "#         cv2.imshow(\"image\", img)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "#             break\n",
    "#\n",
    "#\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
